import streamlit as st
import pandas as pd
import json
import os
import re
import time
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager

# ==========================================
# 1. [í¬ë¡¤ëŸ¬ ë¡œì§] Selenium ê¸°ëŠ¥ í•¨ìˆ˜í™”
# ==========================================
def setup_driver():
    chrome_options = Options()
    # Streamlitì—ì„œ ì‹¤í–‰ ì‹œ ë¸Œë¼ìš°ì € ì°½ì´ ëœ¨ì§€ ì•Šë„ë¡ Headless ëª¨ë“œ ì‚¬ìš© ê¶Œì¥
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
    return driver

def get_data_with_post(driver, page_index=500):
    url = "https://www.goe.go.kr/recruit/ad/func/pb/hnfpPbancList.do"
    
    payload = {
        "mi": "10502",
        "currPage": "1",
        "srchEcptDl": "Y",
        "srchTodayPb": "N",
        "srchOcptNm": "ê¸°ê°„ì œ/ì‚¬ë¦½êµì›",
        "srchOcptCd": "A",
        "pageIndex": str(page_index), # ê°€ì ¸ì˜¬ ê²Œì‹œë¬¼ ìˆ˜
        "orderbyType": "reg",
        "searchType": "sj"
    }

    driver.get(url)
    time.sleep(1) # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°

    js_script = """
    var form = document.createElement("form");
    form.method = "POST";
    form.action = arguments[0];
    var params = arguments[1];

    for (var key in params) {
        if (params.hasOwnProperty(key)) {
            var hiddenField = document.createElement("input");
            hiddenField.type = "hidden";
            hiddenField.name = key;
            hiddenField.value = params[key];
            form.appendChild(hiddenField);
        }
    }
    document.body.appendChild(form);
    form.submit();
    """
    driver.execute_script(js_script, url, payload)
    time.sleep(3) # ë°ì´í„° ë¡œë”© ëŒ€ê¸° (ì¸í„°ë„· ì†ë„ì— ë”°ë¼ ì¡°ì ˆ í•„ìš”)

def parse_recruit_list(driver):
    items = driver.find_elements(By.CSS_SELECTOR, ".recruit_list > ul > li")
    results = []

    for item in items:
        try:
            # 1. pbancSn ì¶”ì¶œ
            anchor = item.find_element(By.TAG_NAME, "a")
            href_value = anchor.get_attribute("href")
            pbanc_sn_match = re.search(r"goView\('(\d+)'\)", href_value)
            pbanc_sn = pbanc_sn_match.group(1) if pbanc_sn_match else ""

            # 2. ìƒë‹¨ ì •ë³´ ì¶”ì¶œ
            top_info = item.find_elements(By.CSS_SELECTOR, ".cont_top > span")
            school = ""
            phone = ""
            reg_date = ""
            
            if top_info:
                school = top_info[0].text.strip()
                for span in top_info[1:]:
                    text = span.text.strip()
                    if "ë“±ë¡ì¼" in text:
                        reg_date = text.replace("ë“±ë¡ì¼", "").replace(":", "").strip()
                    elif "ì¡°íšŒìˆ˜" in text:
                        continue
                    else:
                        phone = text

            # 3. ì œëª© ë° ë±ƒì§€
            title_area = item.find_element(By.CSS_SELECTOR, ".cont_tit")
            badge_text = ""
            badges = title_area.find_elements(By.CLASS_NAME, "krds-badge")
            if badges:
                badge_text = badges[0].text.strip()
            
            full_title = title_area.text.strip()
            pure_title = full_title.replace(badge_text, "").strip()

            # 4. ìƒì„¸ ì •ë³´
            btm_groups = item.find_elements(By.CSS_SELECTOR, ".cont_btm > div")
            group1_ps = btm_groups[0].find_elements(By.TAG_NAME, "p")
            recruit_info = group1_ps[0].find_element(By.TAG_NAME, "span").text.strip()
            recruit_count = group1_ps[1].text.replace("ì±„ìš©ì¸ì›", "").strip()

            group2_ps = btm_groups[1].find_elements(By.TAG_NAME, "p")
            apply_period = group2_ps[0].text.replace("ì ‘ìˆ˜ê¸°ê°„", "").strip()
            work_period = group2_ps[1].text.replace("ì±„ìš©ê¸°ê°„", "").strip()

            job_field = item.find_element(By.CSS_SELECTOR, ".cont_btm > p").text.replace("ì§ë¬´ë¶„ì•¼", "").strip()

            results.append({
                "pbancSn": pbanc_sn,
                "school": school,
                "title": pure_title,
                "badge": badge_text,
                "job_field": job_field if job_field else "ë‚´ìš©ì—†ìŒ",
                "recruit_info": recruit_info,
                "recruit_count": recruit_count,
                "apply_period": apply_period,
                "work_period": work_period,
                "phone": phone,
                "reg_date": reg_date
            })
        except Exception:
            continue
    return results

def crawl_and_save():
    """ì‹¤ì œ í¬ë¡¤ë§ì„ ìˆ˜í–‰í•˜ê³  íŒŒì¼ì„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    driver = setup_driver()
    try:
        # ë°ì´í„° ìˆ˜ì§‘ (500ê°œ ê¸°ì¤€)
        get_data_with_post(driver, page_index=500)
        final_data = parse_recruit_list(driver)
        
        # íŒŒì¼ ì €ì¥
        file_name = "recruit_list.json"
        with open(file_name, "w", encoding="utf-8") as f:
            json.dump(final_data, f, ensure_ascii=False, indent=4)
        
        return len(final_data)
    except Exception as e:
        st.error(f"í¬ë¡¤ë§ ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return 0
    finally:
        driver.quit()

# ==========================================
# 2. [Streamlit UI] í˜ì´ì§€ ì„¤ì • ë° ë¡œì§
# ==========================================
st.set_page_config(page_title="ê²½ê¸°ë„êµìœ¡ì²­ ì±„ìš© ì•Œë¦¼ì´", layout="wide")

# --- ì§ë¬´ ì •ì œ í•¨ìˆ˜ ---
def get_clean_tokens(text):
    tokens = []
    if not isinstance(text, str):
        return tokens
    parts = text.split(',')
    for part in parts:
        clean = re.sub(r'\(.*?\)|[0-9]+|ëª…', '', part)
        clean = re.sub(r'[^ê°€-í£a-zA-Z]', '', clean)
        if clean:
            tokens.append(clean)
    return tokens

def extract_root_subjects(df):
    all_tokens = set()
    if df.empty or 'job_field' not in df.columns:
        return []
    for text in df['job_field']:
        tokens = get_clean_tokens(text)
        all_tokens.update(tokens)
    sorted_tokens = sorted(list(all_tokens), key=len)
    roots = []
    for token in sorted_tokens:
        is_covered = False
        for root in roots:
            if token.startswith(root):
                is_covered = True
                break
        if not is_covered:
            roots.append(token)
    return sorted(roots)

# --- ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_data
def load_data():
    file_path = "recruit_list.json"
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as f:
            try:
                data = json.load(f)
                df = pd.DataFrame(data)
                
                base_url = "https://www.goe.go.kr/recruit/ad/func/pb/hnfpPbancInfoView.do?pbancSn="
                if not df.empty and 'pbancSn' in df.columns:
                    df['ì›ë³¸ë§í¬'] = base_url + df['pbancSn']
                
                def get_region(info_text):
                    if "|" in str(info_text):
                        return str(info_text).split("|")[-1].strip()
                    return "ì§€ì—­ë¯¸ê¸°ì¬"
                
                if not df.empty and 'recruit_info' in df.columns:
                    df['region'] = df['recruit_info'].apply(get_region)
                    
                if not df.empty and 'job_field' in df.columns:
                    df['job_field'] = df['job_field'].fillna("ë‚´ìš©ì—†ìŒ")
                    df['job_field'] = df['job_field'].replace("", "ë‚´ìš©ì—†ìŒ")

                return df
            except json.JSONDecodeError:
                return pd.DataFrame()
    return pd.DataFrame()

# ==========================================
# 3. í™”ë©´ êµ¬ì„± ë° ì‹¤í–‰
# ==========================================

# ì‚¬ì´ë“œë°”: ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ (ê°€ì¥ ìœ„ì— ë°°ì¹˜)
st.sidebar.header("âš™ï¸ ë°ì´í„° ê´€ë¦¬")
if st.sidebar.button("ğŸ”„ ìµœì‹  ê³µê³  ê°€ì ¸ì˜¤ê¸° (í¬ë¡¤ë§)"):
    with st.spinner('ê²½ê¸°ë„êµìœ¡ì²­ ì‚¬ì´íŠ¸ì—ì„œ ìµœì‹  ê³µê³ ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ì•½ 10~15ì´ˆ ì†Œìš”)'):
        # í¬ë¡¤ë§ ì‹¤í–‰
        count = crawl_and_save()
        
    if count > 0:
        st.success(f"ì„±ê³µ! {count}ê°œì˜ ê³µê³ ë¥¼ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤.")
        # ìºì‹œ ë¹„ìš°ê³  í˜ì´ì§€ ë¦¬ë¡œë“œ
        st.cache_data.clear()
        time.sleep(1) # ì‚¬ìš©ìê°€ ë©”ì‹œì§€ë¥¼ ë³¼ ìˆ˜ ìˆê²Œ ì ì‹œ ëŒ€ê¸°
        st.rerun()
    else:
        st.warning("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆê±°ë‚˜ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ë©”ì¸ ë¡œì§ ì‹œì‘
df = load_data()

st.title("ğŸ ê²½ê¸°ë„êµìœ¡ì²­ ì±„ìš© ê³µê³  ëŒ€ì‹œë³´ë“œ (ì—…ë°ì´íŠ¸ ì„±ê³µ!)")

if df.empty:
    st.warning("í˜„ì¬ ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì˜ 'ìµœì‹  ê³µê³  ê°€ì ¸ì˜¤ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
else:
    # --- ì‚¬ì´ë“œë°” í•„í„° ì˜ì—­ ---
    st.sidebar.header("ğŸ” ê²€ìƒ‰ ë° í•„í„°")
    
    search_term = st.sidebar.text_input("í•™êµëª… ë˜ëŠ” ì œëª© ê²€ìƒ‰", "")
    
    unique_regions = sorted(df['region'].unique().tolist())
    if "ì§€ì—­ë¯¸ê¸°ì¬" in unique_regions:
        unique_regions.remove("ì§€ì—­ë¯¸ê¸°ì¬")
        unique_regions.append("ì§€ì—­ë¯¸ê¸°ì¬")
    selected_regions = st.sidebar.multiselect("ì§€ì—­ ì„ íƒ", unique_regions)
    
    subject_roots = extract_root_subjects(df)
    selected_subjects = st.sidebar.multiselect("ì§ë¬´(ê³¼ëª©) ì„ íƒ", subject_roots)

    badges = ["ì „ì²´"] + sorted(df['badge'].unique().tolist())
    selected_badge = st.sidebar.selectbox("ê³µê³  ìƒíƒœ", badges)

    # í•„í„°ë§
    filtered_df = df.copy()

    if search_term:
        filtered_df = filtered_df[
            filtered_df['school'].str.contains(search_term, na=False) | 
            filtered_df['title'].str.contains(search_term, na=False)
        ]
    
    if selected_regions:
        filtered_df = filtered_df[filtered_df['region'].isin(selected_regions)]

    if selected_subjects:
        def check_subject_match(row_text):
            row_tokens = get_clean_tokens(row_text)
            for token in row_tokens:
                for selected in selected_subjects:
                    if token.startswith(selected):
                        return True
            return False
        filtered_df = filtered_df[filtered_df['job_field'].apply(check_subject_match)]

    if selected_badge != "ì „ì²´":
        filtered_df = filtered_df[filtered_df['badge'] == selected_badge]

    # ìš”ì•½ ì •ë³´
    conditions = []
    if search_term: conditions.append(f"ê²€ìƒ‰ì–´: '{search_term}'")
    if selected_regions: conditions.append(f"ì§€ì—­: {', '.join(selected_regions)}")
    if selected_subjects: conditions.append(f"ì§ë¬´: {', '.join(selected_subjects)}")
    if selected_badge != "ì „ì²´": conditions.append(f"ìƒíƒœ: {selected_badge}")

    summary_text = " / ".join(conditions) if conditions else "ì „ì²´ ê³µê³  ì¡°íšŒ ì¤‘"
    st.info(f"ğŸ“‹ **ê²€ìƒ‰ ì¡°ê±´:** {summary_text}")
    st.write(f"âœ… ì¡°ê±´ì— ë§ëŠ” ê³µê³ : **{len(filtered_df)}** ê±´ (ì´ ë°ì´í„°: {len(df)}ê±´)")

    # ê²°ê³¼ í…Œì´ë¸”
    st.dataframe(
        filtered_df, 
        use_container_width=True,
        hide_index=True,
        column_config={
            "pbancSn": None,
            "recruit_info": None,
            "recruit_count": None,
            "region": "ì§€ì—­",
            "school": "í•™êµëª…",
            "title": "ê³µê³  ì œëª©",
            "job_field": "ì§ë¬´(ê³¼ëª©)",
            "badge": "ìƒíƒœ",
            "apply_period": "ì ‘ìˆ˜ ê¸°ê°„",
            "reg_date": "ë“±ë¡ì¼",
            "ì›ë³¸ë§í¬": st.column_config.LinkColumn("ë§í¬", display_text="ê³µê³  ë³´ê¸°")
        }
    )
    
    # ìƒì„¸ ë³´ê¸° (Expander)
    if len(filtered_df) > 0:
        with st.expander("ğŸ”½ ìƒì„¸ ê³µê³  ë¦¬ìŠ¤íŠ¸ ì—´ê¸°/ë‹«ê¸°", expanded=False):
            for i, (index, row) in enumerate(filtered_df.iterrows()):
                title_header = f"[{row['region']}] {row['school']} - {row['title']}"
                if row['badge']: title_header += f" ({row['badge']})"
                
                st.markdown(f"#### {title_header}")
                c1, c2, c3 = st.columns([2, 2, 1])
                with c1:
                    st.caption("ìƒì„¸ì •ë³´")
                    st.write(f"{row['recruit_info']}")
                    st.write(f"**ì§ë¬´:** {row['job_field']}")
                with c2:
                    st.caption("ì¼ì •")
                    st.write(f"ì ‘ìˆ˜: {row['apply_period']}")
                    st.write(f"ì±„ìš©: {row['work_period']}")
                with c3:
                    st.write("")
                    st.link_button("ê³µê³  ë°”ë¡œê°€ê¸°", row['ì›ë³¸ë§í¬'])
                st.divider()

    # ì •ë³´ ëˆ„ë½ ì„¹ì…˜
    st.markdown("---")
    st.subheader("ğŸš¨ ì •ë³´ ëˆ„ë½ ë° ë¶„ë¥˜ ë¶ˆê°€ ê³µê³  (Check List)")
    
    missing_condition = (df['region'] == "ì§€ì—­ë¯¸ê¸°ì¬") | (df['job_field'] == "ë‚´ìš©ì—†ìŒ")
    missing_df = df[missing_condition].copy()

    if search_term:
        missing_df = missing_df[
            missing_df['school'].str.contains(search_term, na=False) | 
            missing_df['title'].str.contains(search_term, na=False)
        ]

    if missing_df.empty:
        st.success("ğŸ‰ í˜„ì¬ ë°ì´í„°ì—ëŠ” ì •ë³´ê°€ ëˆ„ë½ëœ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.error(f"ì´ **{len(missing_df)}** ê±´ì˜ ì •ë³´ ë¶ˆì¶©ë¶„ ê³µê³ ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.dataframe(
            missing_df,
            use_container_width=True,
            hide_index=True,
            column_config={
                "pbancSn": None,
                "recruit_count": None,
                "region": st.column_config.TextColumn("ì§€ì—­", help="ì§€ì—­ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."),
                "job_field": st.column_config.TextColumn("ì§ë¬´", help="ì§ë¬´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."),
                "school": "í•™êµëª…",
                "title": "ê³µê³  ì œëª©",
                "recruit_info": "ìƒì„¸ì •ë³´",
                "ì›ë³¸ë§í¬": st.column_config.LinkColumn("ë§í¬", display_text="í™•ì¸í•˜ê¸°")
            }
        )